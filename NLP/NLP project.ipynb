{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd0eb7d",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebe78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea39d71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset financial_phrasebank (C:\\Users\\korn5\\.cache\\huggingface\\datasets\\financial_phrasebank\\sentences_50agree\\1.0.0\\a6d468761d4e0c8ae215c77367e1092bead39deb08fbf4bffd7c0a6991febbf0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47835debf89c43de845863296e53d8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is a dictionary with two splits: \n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label'],\n",
      "        num_rows: 4846\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"financial_phrasebank\", \n",
    "    'sentences_50agree' # Select variation of the dataset\n",
    ")\n",
    "\n",
    "print(f'The dataset is a dictionary with two splits: \\n\\n{dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117afb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"train\"]['sentence'], \n",
    "    dataset[\"train\"]['label'], \n",
    "    test_size=0.2, \n",
    "    stratify=dataset[\"train\"]['label']  # make sure the same proportion of labels is in the test set and training set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a15b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the train dataset? \n",
      "\n",
      "3876\n",
      "\n",
      "What does one instance look like? \n",
      "\n",
      "More than 50,000 tonnes of asphalt mix will be used in the contract .\n"
     ]
    }
   ],
   "source": [
    "# label 0 = negative, 1 = neutral, 2 = positive\n",
    "print(f'How many instances in the train dataset? \\n\\n{len(train_sentences)}')\n",
    "print('')\n",
    "print(f'What does one instance look like? \\n\\n{train_sentences[234]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b93bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences, train_labels, test_size=0.25, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48fb45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many instances in the validation dataset? \n",
      "\n",
      "969\n",
      "\n",
      "How many instances in the test dataset? \n",
      "\n",
      "970\n"
     ]
    }
   ],
   "source": [
    "print(f'How many instances in the validation dataset? \\n\\n{len(val_sentences)}\\n')\n",
    "print(f'How many instances in the test dataset? \\n\\n{len(test_sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbe12ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Last week , the Finnish metals and technology group announced plans to sell more than 80 percent of its technology unit to further the company 's strategic goal of becoming the world 's largest stainless steel maker .\",\n",
       " 'Revenue was slightly down , at  x20ac 495 million $ 634 million , compared to  x20ac 497 million a year earlier .',\n",
       " '2010 16 July 2010 - Finnish steel maker Rautaruukki Oyj HEL : RTRKS , or Ruukki , said today it turned to a net profit of EUR20m in the second quarter of 2010 from a net loss of EUR94m in the corresponding period last year .']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ceb8b",
   "metadata": {},
   "source": [
    "## BOW feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5a7665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korn5\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __call__(self, sent):\n",
    "        return word_tokenize(sent)\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=Tokenizer()) \n",
    "\n",
    "vectorizer.fit(train_sentences)  # Learn the vocabulary\n",
    "X_train = vectorizer.transform(train_sentences)  # extract training set bags of words\n",
    "X_val = vectorizer.transform(val_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49dd8c",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719d8746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korn5\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42a9b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = classifier.predict(X_val)\n",
    "y_train_pred = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331f4748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.62       121\n",
      "           1       0.81      0.89      0.85       576\n",
      "           2       0.69      0.64      0.66       272\n",
      "\n",
      "    accuracy                           0.77       969\n",
      "   macro avg       0.75      0.69      0.71       969\n",
      "weighted avg       0.77      0.77      0.77       969\n",
      "\n",
      " macro avg f1 score of traning set is 0.9953618846096085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,f1_score\n",
    "print(classification_report(val_labels, y_val_pred))\n",
    "print(f' macro avg f1 score of traning set is {f1_score(y_train_pred,train_labels,average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e12596ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Three students from Universiti Sains Malaysia have won a study trip to Helsinki .; true label = 1, prediction = 2.\n",
      "Tweet: For 24-hour news , try ICIS news www.icis.com Click `` trial '' , then ICIS news; true label = 1, prediction = 2.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "error_indexes = y_val_pred != val_labels  # compare predictions to gold labels\n",
    "\n",
    "# get the text of tweets where the classifier made an error:\n",
    "sentences_err = np.array(val_sentences)[error_indexes]\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "pred_err = y_val_pred[error_indexes]\n",
    "gold_err = np.array(val_labels)[error_indexes]\n",
    "\n",
    "for i in range(2):  # just print the first ten\n",
    "    print(f'Tweet: {sentences_err[i]}; true label = {gold_err[i]}, prediction = {pred_err[i]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1ef3f",
   "metadata": {},
   "source": [
    "### using Bi gram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45527194",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(tokenizer=Tokenizer(),ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a3397eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korn5\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer.fit(train_sentences)\n",
    "X_train_ngram = ngram_vectorizer.transform(train_sentences)\n",
    "X_val_ngram = ngram_vectorizer.transform(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46682827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ngram = LogisticRegression()\n",
    "classifier_ngram.fit(X_train_ngram, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c8f6266",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.36      0.51       121\n",
      "           1       0.74      0.97      0.84       576\n",
      "           2       0.76      0.46      0.57       272\n",
      "\n",
      "    accuracy                           0.75       969\n",
      "   macro avg       0.79      0.59      0.64       969\n",
      "weighted avg       0.76      0.75      0.72       969\n",
      "\n",
      " macro avg f1 score of traning set is  1.0\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_ngram = classifier_ngram.predict(X_val_ngram)\n",
    "y_train_pred_ngram = classifier_ngram.predict(X_train_ngram)\n",
    "print(classification_report(val_labels, y_val_pred_ngram))\n",
    "print(f' macro avg f1 score of traning set is  {f1_score(y_train_pred_ngram,train_labels, average= \"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22a9b1",
   "metadata": {},
   "source": [
    "### using Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb1a4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\korn5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, sent):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(sent)]\n",
    "    \n",
    "lemma_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edfd1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_vectorizer.fit(train_sentences)\n",
    "X_train_lemma = lemma_vectorizer.transform(train_sentences)\n",
    "X_val_lemma = lemma_vectorizer.transform(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d245b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korn5\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lemma = LogisticRegression()\n",
    "classifier_lemma.fit(X_train_lemma, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbfea99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.55      0.63       121\n",
      "           1       0.80      0.87      0.84       576\n",
      "           2       0.68      0.63      0.65       272\n",
      "\n",
      "    accuracy                           0.76       969\n",
      "   macro avg       0.74      0.69      0.71       969\n",
      "weighted avg       0.76      0.76      0.76       969\n",
      "\n",
      " macro avg f1 score of traning set is 0.9929891382839987\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_lemma = classifier_lemma.predict(X_val_lemma)\n",
    "y_train_pred_lemma = classifier_lemma.predict(X_train_lemma)\n",
    "print(classification_report(val_labels, y_val_pred_lemma))\n",
    "print(f' macro avg f1 score of traning set is {f1_score(y_train_pred_lemma,train_labels,average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22802db",
   "metadata": {},
   "source": [
    "### using both  lemmatization and  bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1361c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_bi_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c92b0540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korn5\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lemma_bi_vectorizer.fit(train_sentences)\n",
    "X_train_lemma_bi = lemma_bi_vectorizer.transform(train_sentences)\n",
    "X_val_lemma_bi = lemma_bi_vectorizer.transform(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d43831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.36      0.50       121\n",
      "           1       0.74      0.96      0.84       576\n",
      "           2       0.75      0.47      0.58       272\n",
      "\n",
      "    accuracy                           0.75       969\n",
      "   macro avg       0.78      0.60      0.64       969\n",
      "weighted avg       0.76      0.75      0.72       969\n",
      "\n",
      " macro avg f1 score of traning set is 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train_lemma_bi, train_labels)\n",
    "y_val_pred_lemma_bi = classifier.predict(X_val_lemma_bi)\n",
    "y_train_pred_lemma_bi = classifier.predict(X_train_lemma_bi)\n",
    "print(classification_report(val_labels, y_val_pred_lemma_bi))\n",
    "print(f' macro avg f1 score of traning set is {f1_score(y_train_pred_lemma_bi,train_labels,average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138e93d",
   "metadata": {},
   "source": [
    "## Test using Lemmatization and uni-gram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a65d518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.59      0.68       121\n",
      "           1       0.80      0.89      0.84       576\n",
      "           2       0.71      0.63      0.67       273\n",
      "\n",
      "    accuracy                           0.78       970\n",
      "   macro avg       0.77      0.70      0.73       970\n",
      "weighted avg       0.77      0.78      0.77       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_lemma = lemma_vectorizer.transform(test_sentences)\n",
    "y_test_pred = classifier_lemma.predict(X_test_lemma)\n",
    "print(classification_report(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cdcb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0501ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korn5\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2e89cbff160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(classifier_lemma, X_test_lemma, test_labels,cmap = 'GnBu')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d74cef",
   "metadata": {},
   "source": [
    "# Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbf7d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def read_sec_filings(split):\n",
    "    # Use this function to load the SEC filings data from text files\n",
    "    \n",
    "    if split == 'train':\n",
    "        with open('C:/Users/korn5/OneDrive - University of Bristol/Data Sci/TB2/INDA/coursework/SEC-filings/SEC-filings/train/FIN5.txt',\n",
    "                  encoding='utf-8') as fp:\n",
    "            lines = fp.readlines()\n",
    "    else:\n",
    "        with open('C:/Users/korn5/OneDrive - University of Bristol/Data Sci/TB2/INDA/coursework/SEC-filings/SEC-filings/test/FIN3.txt',\n",
    "                  encoding='utf-8') as fp:\n",
    "            lines = fp.readlines()\n",
    "   \n",
    "    # store the tokens and labels for all sentences\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    # the tokens and labels for the current sentence\n",
    "    current_sen = []\n",
    "    current_labels = []\n",
    "\n",
    "    for i in range(2, len(lines)):\n",
    "        # print(f'This is line {i}')\n",
    "        # print(lines[i])\n",
    "\n",
    "        if len(lines[i]) > 1:  # Line with some data on: The data consists of tokens and tags.\n",
    "            data = re.split(' ', lines[i])  # tokenise the line\n",
    "            # print(data)\n",
    "            current_sen.append(data[0])  # append the token \n",
    "            \n",
    "            # data[1] contains POS tags -- you can also use these in your model.\n",
    "            \n",
    "            current_labels.append(data[3].strip())  # append the NER tag\n",
    "        elif len(current_sen) > 1:  # this marks the end of a sentence\n",
    "            # end of sentence\n",
    "            sentences.append(current_sen)  # save the tokens for this sentence\n",
    "            current_sen = []  # reset\n",
    "\n",
    "            labels.append(current_labels)  # save the tags for this sentence\n",
    "            current_labels = []\n",
    "\n",
    "    if len(current_sen) > 1:  # save the last sentence\n",
    "        sentences.append(current_sen)\n",
    "        labels.append(current_labels)\n",
    "    \n",
    "    print(f'Number of sentences loaded = {len(sentences)}')\n",
    "    print(f'Number of unique labels: {np.unique(np.concatenate(labels))}')\n",
    "                                      \n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e813200",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the original training set: \n",
      "Number of sentences loaded = 1152\n",
      "Number of unique labels: ['I-LOC' 'I-MISC' 'I-ORG' 'I-PER' 'O']\n",
      "\n",
      "Loading the test set: \n",
      "Number of sentences loaded = 303\n",
      "Number of unique labels: ['I-LOC' 'I-MISC' 'I-ORG' 'I-PER' 'O']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Loading the original training set: ')\n",
    "sentences_ner, labels_ner = read_sec_filings('train')\n",
    "\n",
    "print('\\nLoading the test set: ')\n",
    "test_sentences_ner, test_labels_ner = read_sec_filings('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a5ac30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 921\n",
      "Number of validation sentences = 231\n"
     ]
    }
   ],
   "source": [
    "train_sentences_ner, val_sentences_ner, train_labels_ner, val_labels_ner = train_test_split(\n",
    "    sentences_ner, \n",
    "    labels_ner, \n",
    "    test_size=0.2,\n",
    "    # stratify=labels_ner  # there are too few examples of some classes to stratify\n",
    ")\n",
    "\n",
    "print(f'Number of training sentences = {len(train_sentences_ner)}')\n",
    "print(f'Number of validation sentences = {len(val_sentences_ner)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8c390",
   "metadata": {},
   "source": [
    "### data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc346640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [list(zip([tok for tok in train_sentences_ner[i]], [label for label in train_labels_ner[i]])) for i in range (len(train_sentences_ner))][:-1]\n",
    "val_set = [list(zip([tok for tok in val_sentences_ner[i]], [label for label in val_labels_ner[i]])) for i in range (len(val_sentences_ner))][:-1]\n",
    "test_set = [list(zip([tok for tok in test_sentences_ner[i]], [label for label in test_labels_ner[i]])) for i in range (len(test_sentences_ner))][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a62ff",
   "metadata": {},
   "source": [
    "### CRF without feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daf6bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Train a CRF NER tagger\n",
    "def train_CRF_NER_tagger(train_set):\n",
    "    tagger = nltk.tag.CRFTagger()\n",
    "    tagger.train(train_set, 'model.crf.tagger')\n",
    "    return tagger \n",
    "\n",
    "tagger = train_CRF_NER_tagger(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05789783",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags = tagger.tag_sents(val_sentences_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32c498ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class PER = 0.9652777777777778\n",
      "F1 score for class LOC = 0.64\n",
      "F1 score for class MISC = 0\n",
      "F1 score for class ORG = 0.8958333333333334\n",
      "Macro-average f1 score = 0.6252777777777778\n"
     ]
    }
   ],
   "source": [
    "def extract_spans(tagged_sents):\n",
    "    \"\"\"\n",
    "    Extract a list of tagged spans for each named entity type, \n",
    "    where each span is represented by a tuple containing the \n",
    "    start token and end token indexes.\n",
    "    \n",
    "    returns: a dictionary containing a list of spans for each entity type.\n",
    "    \"\"\"\n",
    "    spans = {}\n",
    "        \n",
    "    for sidx, sent in enumerate(tagged_sents):\n",
    "        start = -1\n",
    "        entity_type = None\n",
    "        for i, (tok, lab) in enumerate(sent):\n",
    "            if 'I-' in lab and start == -1:\n",
    "                start = i\n",
    "                end = i + 1\n",
    "                entity_type = lab[2:]\n",
    "                \n",
    "            elif 'I-' in lab and start >= 0:\n",
    "                if lab == sent[i-1][1]:\n",
    "                    end = i+1\n",
    "                else:\n",
    "                    start = i\n",
    "                    end = i+1 \n",
    "                    entity_type = lab[2:]\n",
    "                \n",
    "            elif lab == 'O' and start >= 0:\n",
    "                if entity_type not in spans:\n",
    "                    spans[entity_type] = []\n",
    "                \n",
    "                spans[entity_type].append((start, end, sidx))\n",
    "                start = -1\n",
    "                \n",
    "    return spans\n",
    "\n",
    "\n",
    "def cal_span_level_f1(test_sents, test_sents_with_pred):\n",
    "    # get a list of spans from the test set labels\n",
    "    gold_spans = extract_spans(test_sents)\n",
    "    \n",
    "    # get a list of spans predicted by our tagger\n",
    "    pred_spans = extract_spans(test_sents_with_pred)\n",
    "    pred_type = pred_spans.keys()\n",
    "    \n",
    "    # compute the metrics for each class:\n",
    "    f1_per_class = []\n",
    "    \n",
    "    ne_types = gold_spans.keys()  # get the list of named entity types (not the tags)\n",
    "    \n",
    "    for ne_type in ne_types:\n",
    "        # compute the confusion matrix\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        \n",
    "        if ne_type not in pred_type:\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            for span in pred_spans[ne_type]:\n",
    "                if span in gold_spans[ne_type]:\n",
    "                    true_pos += 1\n",
    "                else:\n",
    "                    false_pos += 1\n",
    "                \n",
    "        false_neg = 0\n",
    "        if ne_type not in pred_type:\n",
    "            false_neg += 0\n",
    "        else:\n",
    "            for span in gold_spans[ne_type]:\n",
    "                if span not in pred_spans[ne_type]:\n",
    "                    false_neg += 1\n",
    "                \n",
    "        if true_pos + false_pos == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = true_pos / float(true_pos + false_pos)\n",
    "            \n",
    "        if true_pos + false_neg == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = true_pos / float(true_pos + false_neg)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "            \n",
    "        f1_per_class.append(f1)\n",
    "        \n",
    "        \n",
    "        print(f'F1 score for class {ne_type} = {f1}')\n",
    "        \n",
    "    print(f'Macro-average f1 score = {np.mean(f1_per_class)}')\n",
    "    \n",
    "cal_span_level_f1(val_set, predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c775e2",
   "metadata": {},
   "source": [
    "### add feature for CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45c46d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata\n",
    "\n",
    "class CustomCRFTagger(nltk.tag.CRFTagger):\n",
    "    _current_tokens = None\n",
    "    \n",
    "    def _get_features(self, tokens, idx):\n",
    "            \"\"\"\n",
    "            Extract basic features about this word including\n",
    "                - Current word\n",
    "                - is it capitalized?\n",
    "                - Does it have punctuation?\n",
    "                - Does it have a number?\n",
    "                - Suffixes up to length 3\n",
    "\n",
    "            Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "            :return: a list which contains the features\n",
    "            :rtype: list(str)\n",
    "            \"\"\"\n",
    "            token = tokens[idx]\n",
    "\n",
    "            feature_list = []\n",
    "\n",
    "            if not token:\n",
    "                return feature_list\n",
    "\n",
    "            # Capitalization\n",
    "            if token[0].isupper():\n",
    "                feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "            # Number\n",
    "            if re.search(self._pattern, token) is not None:\n",
    "                feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "            # Punctuation\n",
    "            punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "            if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "                feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "            # Suffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"SUF_\" + token[-1:])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"SUF_\" + token[-2:])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"SUF_\" + token[-3:])\n",
    "\n",
    "                \n",
    "            # Current word\n",
    "            feature_list.append(\"WORD_\" + token)\n",
    "            \n",
    "            \n",
    "            if idx > 0:\n",
    "                feature_list.append(\"PREVWORD_\" + tokens[idx-1])\n",
    "            if idx < len(tokens)-1:\n",
    "                feature_list.append(\"NEXTWORD_\" + tokens[idx+1])\n",
    "                \n",
    "#             print(feature_list)  \n",
    "#             print(token)\n",
    "\n",
    "            return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffeba752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Improve the CRF NER tagger using parts of speech\n",
    "class CRFTaggerWithPOS(CustomCRFTagger):\n",
    "    _current_tokens = None\n",
    "    \n",
    "    def _get_features(self, tokens, index):\n",
    "        \"\"\"\n",
    "        Extract the features for a token and append the POS tag as an additional feature.\n",
    "        \"\"\"\n",
    "        basic_features = super()._get_features(tokens, index)\n",
    "        \n",
    "        # Get the pos tags for the current sentence and save it\n",
    "        if tokens != self._current_tokens:\n",
    "            self._pos_tagged_tokens = nltk.pos_tag(tokens)\n",
    "            self._current_tokens = tokens\n",
    "            \n",
    "        basic_features.append(self._pos_tagged_tokens[index][1])\n",
    "#         print(basic_features)\n",
    "        \n",
    "        return basic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c861dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CRF_NER_tagger_with_POS(train_set):\n",
    "    tagger = CRFTaggerWithPOS()\n",
    "    tagger.train(train_set, 'model.crf.tagger')\n",
    "    return tagger  # return the trained model\n",
    "\n",
    "tagger_with_POS = train_CRF_NER_tagger_with_POS(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f937e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class PER = 0.9757785467128028\n",
      "F1 score for class LOC = 0.7857142857142856\n",
      "F1 score for class MISC = 0\n",
      "F1 score for class ORG = 0.8775510204081634\n",
      "Macro-average f1 score = 0.659760963208813\n"
     ]
    }
   ],
   "source": [
    "predicted_tags = tagger_with_POS.tag_sents(val_sentences_ner)\n",
    "cal_span_level_f1(val_set, predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bbb88",
   "metadata": {},
   "source": [
    "### Use CRF with POS tagging model with testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5900741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class ORG = 0.34408602150537637\n",
      "F1 score for class PER = 0.8930232558139536\n",
      "F1 score for class LOC = 0.37499999999999994\n",
      "F1 score for class MISC = 0\n",
      "Macro-average f1 score = 0.4030273193298325\n"
     ]
    }
   ],
   "source": [
    "predicted_tags_test = tagger_with_POS.tag_sents(test_sentences_ner)\n",
    "cal_span_level_f1(test_set, predicted_tags_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c487e",
   "metadata": {},
   "source": [
    "## 2.4  Apply your trained NER tagger to the Financial Phrasebank dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26c1817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents = []\n",
    "\n",
    "labs = dataset[\"train\"]['label']\n",
    "sents = dataset[\"train\"]['sentence']\n",
    "for sent in dataset[\"train\"]['sentence']:\n",
    "    tokens = nltk.word_tokenize(sent) \n",
    "    tokenized_sents.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f92d1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply model with the data set\n",
    "predicted_data = tagger.tag_sents(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80b5a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract entities\n",
    "span = extract_spans(predicted_data)\n",
    "org = span['ORG']\n",
    "entities = []\n",
    "sentiment = []\n",
    "for i in org:\n",
    "    word =  [i for i, j in predicted_data[i[2]][i[0]:i[1]]]\n",
    "    lab = labs[i[2]]\n",
    "    entities.append(' '.join(word))\n",
    "    sentiment.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7efd9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = np.unique(entities)\n",
    "pos_score = np.zeros(len(unique))\n",
    "neg_score = np.zeros(len(unique))\n",
    "for i, entity in enumerate(entities):\n",
    "    for j, u in enumerate(unique):\n",
    "        if (entity == u) and (sentiment[i] == 2):\n",
    "            pos_score[j] += 1\n",
    "        elif (entity == u) and (sentiment[i] == 0):\n",
    "            neg_score[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18974916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ORG: Kaupthing Bank, sentiment score: 2.0\n",
      " ORG: Kai, sentiment score: 2.0\n",
      " ORG: Finnish Ahlstrom Corporation, sentiment score: 2.0\n",
      " ORG: Stonesoft Oyj, sentiment score: 2.0\n",
      " ORG: HELSINKI AFX, sentiment score: 3.0\n"
     ]
    }
   ],
   "source": [
    "#the most 5 positive word\n",
    "pos_idx = np.argsort((pos_score - neg_score))[-5:]\n",
    "for idx in pos_idx:\n",
    "    print(f' ORG: {unique[idx]}, sentiment score: {(pos_score - neg_score)[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38630324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ORG: The OMX Helsinki, sentiment score: -2.0\n",
      " ORG: Swedbank, sentiment score: -2.0\n",
      " ORG: Bank, sentiment score: -2.0\n",
      " ORG: Orion Corporation OMX Helsinki, sentiment score: -1.0\n",
      " ORG: EMSA, sentiment score: -1.0\n"
     ]
    }
   ],
   "source": [
    "#the most 5 negative word\n",
    "neg_idx = np.argsort((pos_score - neg_score))[:5]\n",
    "for idx in neg_idx:\n",
    "    print(f' ORG: {unique[idx]}, sentiment score: {(pos_score - neg_score)[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
